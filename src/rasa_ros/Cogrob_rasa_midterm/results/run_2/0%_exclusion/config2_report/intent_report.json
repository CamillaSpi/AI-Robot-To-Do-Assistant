{
  "view_activities": {
    "precision": 0.8,
    "recall": 1.0,
    "f1-score": 0.888888888888889,
    "support": 8,
    "confused_with": {}
  },
  "modify_category": {
    "precision": 0.8888888888888888,
    "recall": 1.0,
    "f1-score": 0.9411764705882353,
    "support": 8,
    "confused_with": {}
  },
  "affirm": {
    "precision": 0.5,
    "recall": 0.5,
    "f1-score": 0.5,
    "support": 2,
    "confused_with": {
      "inform": 1
    }
  },
  "clean_activities": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3,
    "confused_with": {}
  },
  "view_categories": {
    "precision": 1.0,
    "recall": 0.6666666666666666,
    "f1-score": 0.8,
    "support": 3,
    "confused_with": {
      "view_activities": 1
    }
  },
  "ask_name": {
    "precision": 0.25,
    "recall": 0.6666666666666666,
    "f1-score": 0.36363636363636365,
    "support": 3,
    "confused_with": {
      "modify_category": 1
    }
  },
  "help": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "mood_great": {
    "precision": 0.6666666666666666,
    "recall": 0.6666666666666666,
    "f1-score": 0.6666666666666666,
    "support": 3,
    "confused_with": {
      "greet": 1
    }
  },
  "add_item": {
    "precision": 0.8870967741935484,
    "recall": 0.9821428571428571,
    "f1-score": 0.9322033898305085,
    "support": 56,
    "confused_with": {
      "modify_activity_category": 1
    }
  },
  "remove_category": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 12,
    "confused_with": {}
  },
  "deny": {
    "precision": 0.5,
    "recall": 0.6666666666666666,
    "f1-score": 0.5714285714285715,
    "support": 3,
    "confused_with": {
      "affirm": 1
    }
  },
  "goodbye": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 2,
    "confused_with": {
      "presentation": 1,
      "greet": 1
    }
  },
  "modify_activity_deadline": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 12,
    "confused_with": {}
  },
  "remind_me_of": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7,
    "confused_with": {}
  },
  "presentation": {
    "precision": 0.8421052631578947,
    "recall": 0.4444444444444444,
    "f1-score": 0.5818181818181818,
    "support": 36,
    "confused_with": {
      "inform": 11,
      "ask_name": 4
    }
  },
  "greet": {
    "precision": 0.2,
    "recall": 0.5,
    "f1-score": 0.28571428571428575,
    "support": 2,
    "confused_with": {
      "ask_name": 1
    }
  },
  "remove_item": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 23,
    "confused_with": {}
  },
  "inform": {
    "precision": 0.75,
    "recall": 0.8181818181818182,
    "f1-score": 0.7826086956521738,
    "support": 44,
    "confused_with": {
      "add_item": 2,
      "presentation": 2
    }
  },
  "set_status_activity": {
    "precision": 0.9285714285714286,
    "recall": 0.8125,
    "f1-score": 0.8666666666666666,
    "support": 16,
    "confused_with": {
      "add_item": 3
    }
  },
  "bot_challenge": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "ask_name": 1
    }
  },
  "mood_unhappy": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "add_category": {
    "precision": 1.0,
    "recall": 0.8181818181818182,
    "f1-score": 0.9,
    "support": 11,
    "confused_with": {
      "add_item": 2
    }
  },
  "modify_activity_name": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 21,
    "confused_with": {}
  },
  "modify_activity_category": {
    "precision": 0.9444444444444444,
    "recall": 1.0,
    "f1-score": 0.9714285714285714,
    "support": 17,
    "confused_with": {}
  },
  "accuracy": 0.8552188552188552,
  "macro avg": {
    "precision": 0.756573894413453,
    "recall": 0.7725882335257336,
    "f1-score": 0.7521765313466298,
    "support": 297
  },
  "weighted avg": {
    "precision": 0.8722795230718265,
    "recall": 0.8552188552188552,
    "f1-score": 0.8528004229564021,
    "support": 297
  }
}